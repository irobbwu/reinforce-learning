{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d38cb9-ef7a-492a-9e70-7700a4466607",
   "metadata": {},
   "source": [
    "# Reinforce-Prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d712b4-3dc5-4156-9d8a-a1d4b8593e21",
   "metadata": {},
   "source": [
    "## BaseLine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d7dae8-7e04-4dc8-8893-c777ad5c9961",
   "metadata": {},
   "source": [
    "作为第一个示例，令Q1和Q2都等于某个小的正数，而Q3等于一个\r\n",
    "大的负数。因此，第一步和第二步的动作得到了一些小的奖励，但是\r\n",
    "第三步并不是很成功。由这三个步骤所产生的综合梯度将试图使策略\r\n",
    "远离第三步的动作，而稍微朝第一步和第二步采取的动作靠拢，这是\r\n",
    "完全合理的。\r\n",
    "\r\n",
    "\r\n",
    "现在让我们想象一下，假设奖励永远是正的，只有价值不同。这\r\n",
    "对应于为每个奖励（Q1、Q2和Q3）加上一些常数。在这种情况下，Q1\r\n",
    "和Q2将变为较大的正数，而Q3为较小的正值。但是，策略更新将有所\r\n",
    "不同！接下来，我们将努力将策略推向第一步和第二步的动作，并略\r\n",
    "微将其推向第三步的动作。因此，严格来说，尽管相对奖励是相同\r\n",
    "的，但我们不再试图避免选择第三步所执行的动作。\r\n",
    "\r\n",
    "策略更新依赖于奖励中所加的常数，这可能会大大减慢训练速\r\n",
    "度，因为我们可能需要更多样本来平均掉这种策略梯度偏移的影响。\r\n",
    "甚至更糟的是，由于折扣总奖励随时间变化，随着智能体学着如何表\r\n",
    "现得越来越好，策略梯度的方差也可能发生变化。\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8cbd39d-55b9-4ddf-9813-67b697fcd670",
   "metadata": {},
   "source": [
    "## Monte Carlo policy gradient (REINFORCE)\n",
    "- 1、用随机权重初始化策略网络\n",
    "- 2、运行N个完整的片段，保存其(s,a,r,s')状态转移\n",
    "- 3、对于每个片段k的每一步t，计算后续步的带折扣的总奖励$Q_{k,t}=\\sum_{i\\in T}\\gamma_ir_i - \\frac{1}{n}\\sum_{i\\in T}\\gamma_ir_i$\n",
    "- 4、计算所有状态转移的损失函数 $L=-\\sum_{k,t}Q_{k,t}ln\\pi(a_{k,t}|s_{k,t})$\n",
    "- 5、执行SGD更新权重，以最小化损失\n",
    "- 6、从步骤2开始重复，直到收敛"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ce6acc7-0240-4ce8-a222-6079032fe40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import copy\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "import gym\n",
    "import gym.spaces\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from gym.envs.toy_text import frozen_lake\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ea3371-a7df-4f29-b31e-63f6a368e5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、用随机权重初始化策略网络\n",
    "class PolicyNet(nn.Module):\n",
    "    def __init__(self, obs_n, hidden_num, act_n):\n",
    "        super().__init__()\n",
    "        # 动作优势A(s, a)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(obs_n, hidden_num),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_num, act_n),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "    def forward(self, state):\n",
    "        if len(torch.Tensor(state).size()) == 1:\n",
    "            state = state.reshape(1, -1)\n",
    "        return self.net(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d513a12-e0c1-4c2c-87fa-7444e781b975",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_reward(R, gamma):\n",
    "    # r 为历史得分\n",
    "    n = len(R)\n",
    "    dr = 0\n",
    "    for i in range(n):\n",
    "        dr += gamma**i * R[i]\n",
    "    return dr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a88f07dc-eac3-4ca7-9b46-429290fe1c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - 2、运行N个完整的片段，保存其(s,a,r,s')状态转移\n",
    "def generate_episode(env, n_steps, net, predict=False):\n",
    "    episode_history = dict()\n",
    "    r_list = []\n",
    "\n",
    "    for _ in range(n_steps):\n",
    "        episode = []\n",
    "        predict_reward = []\n",
    "        state, info = env.reset()\n",
    "        while True:\n",
    "            p = net(torch.Tensor(state)).detach().numpy().reshape(-1)\n",
    "            action = np.random.choice(list(range(env.action_space.n)), p=p)\n",
    "            next_state, reward, terminated, truncted, info = env.step(action)\n",
    "            episode.append([state, action, next_state, reward, terminated])\n",
    "            predict_reward.append(reward)\n",
    "            state = next_state\n",
    "            if terminated or truncted:\n",
    "                episode_history[_] = episode\n",
    "                r_list.append(len(episode))\n",
    "                episode = []\n",
    "                predict_reward = []\n",
    "                break\n",
    "    if predict:\n",
    "        return np.mean(r_list)\n",
    "    return episode_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "514034c6-ebfe-4f68-b5da-c8e12846007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于每个片段k的每一步t，计算后续步的带折扣的总奖励\n",
    "def calculate_t_discount_reward(reward_list, gamma, baseline=False):\n",
    "    discount_reward = []\n",
    "    total_reward = 0\n",
    "    for i in reward_list[::-1]:\n",
    "        total_reward = total_reward * gamma + i\n",
    "        if baseline:\n",
    "            discount_reward.append(total_reward - np.mean(reward_list))\n",
    "        else:\n",
    "            discount_reward.append(total_reward)\n",
    "    return discount_reward[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8032a363-8086-444c-b1c9-e64bf0028d07",
   "metadata": {},
   "source": [
    "- 4、计算所有状态转移的损失函数 $L=-\\sum_{k,t}Q_{k,t}ln\\pi(a_{k,t}|s_{k,t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08dbad5b-e674-4faa-b767-75f7b98e3b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(batch, gamma):\n",
    "    l = 0\n",
    "    for episode in batch.values():\n",
    "        reward_list = [\n",
    "            reward for state, action, next_state, reward, terminated in episode\n",
    "        ]\n",
    "        state = [state for state, action, next_state, reward, terminated in episode]\n",
    "        action = [action for state, action, next_state, reward, terminated in episode]\n",
    "        qt = calculate_t_discount_reward(reward_list, gamma, True)\n",
    "        pi = net(torch.Tensor(state))\n",
    "        pi = pi.gather(dim=1, index=torch.LongTensor(action).reshape(-1, 1))\n",
    "        l -= torch.Tensor(qt) @ torch.log(pi)\n",
    "    return l / len(batch.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9945a8ab-4530-4126-8e42-29b33510bec4",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d9802e9-7ac7-40b9-b486-54bfbca4f59d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 初始化环境\n",
    "env = gym.make(\"CartPole-v1\", max_episode_steps=200)\n",
    "# env = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "obs_n = env.observation_space.shape[0]\n",
    "hidden_num = 64\n",
    "act_n = env.action_space.n\n",
    "net = PolicyNet(obs_n, hidden_num, act_n)\n",
    "\n",
    "# 定义优化器\n",
    "opt = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# 记录\n",
    "writer = SummaryWriter(\n",
    "    log_dir=\"logs/PolicyGradient/reinforce-baseline\", comment=\"test1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a139fd67-3953-4e97-aec1-b392bcda6311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wu.zhengzhen\\AppData\\Local\\Temp\\ipykernel_12956\\1800357263.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  pi = net(torch.Tensor(state))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,  Loss: tensor([87.4521]), max_steps: 26.1\n",
      "epoch:1,  Loss: tensor([123.9768]), max_steps: 32.9\n",
      "epoch:2,  Loss: tensor([195.3206]), max_steps: 35.2\n",
      "epoch:3,  Loss: tensor([134.8634]), max_steps: 34.5\n",
      "epoch:4,  Loss: tensor([163.0333]), max_steps: 45.9\n",
      "epoch:5,  Loss: tensor([203.7186]), max_steps: 49.0\n",
      "epoch:6,  Loss: tensor([240.0397]), max_steps: 47.4\n",
      "epoch:7,  Loss: tensor([265.6391]), max_steps: 83.6\n",
      "epoch:8,  Loss: tensor([257.5919]), max_steps: 63.5\n",
      "epoch:9,  Loss: tensor([287.2999]), max_steps: 71.1\n",
      "epoch:10,  Loss: tensor([359.1578]), max_steps: 83.0\n",
      "epoch:11,  Loss: tensor([401.5188]), max_steps: 88.4\n",
      "epoch:12,  Loss: tensor([477.2301]), max_steps: 94.7\n",
      "epoch:13,  Loss: tensor([393.0710]), max_steps: 115.1\n",
      "epoch:14,  Loss: tensor([691.4105]), max_steps: 133.6\n",
      "epoch:15,  Loss: tensor([592.6606]), max_steps: 108.6\n",
      "epoch:16,  Loss: tensor([711.7249]), max_steps: 151.7\n",
      "epoch:17,  Loss: tensor([663.7057]), max_steps: 132.0\n",
      "epoch:18,  Loss: tensor([686.0579]), max_steps: 136.0\n",
      "epoch:19,  Loss: tensor([600.0414]), max_steps: 133.8\n",
      "epoch:20,  Loss: tensor([724.8401]), max_steps: 156.8\n",
      "epoch:21,  Loss: tensor([760.0555]), max_steps: 171.2\n",
      "epoch:22,  Loss: tensor([812.5968]), max_steps: 167.7\n",
      "epoch:23,  Loss: tensor([820.7651]), max_steps: 183.9\n",
      "epoch:24,  Loss: tensor([864.8804]), max_steps: 195.0\n",
      "epoch:25,  Loss: tensor([915.5966]), max_steps: 188.2\n",
      "epoch:26,  Loss: tensor([874.5269]), max_steps: 167.0\n",
      "epoch:27,  Loss: tensor([834.4391]), max_steps: 182.5\n",
      "epoch:28,  Loss: tensor([911.7562]), max_steps: 168.5\n",
      "epoch:29,  Loss: tensor([794.9540]), max_steps: 178.0\n",
      "epoch:30,  Loss: tensor([813.6176]), max_steps: 176.6\n",
      "epoch:31,  Loss: tensor([818.1777]), max_steps: 171.9\n",
      "epoch:32,  Loss: tensor([723.6990]), max_steps: 161.2\n",
      "epoch:33,  Loss: tensor([911.6481]), max_steps: 197.6\n",
      "epoch:34,  Loss: tensor([868.4109]), max_steps: 157.7\n",
      "epoch:35,  Loss: tensor([835.1416]), max_steps: 163.2\n",
      "epoch:36,  Loss: tensor([735.8556]), max_steps: 161.8\n",
      "epoch:37,  Loss: tensor([746.2830]), max_steps: 162.2\n",
      "epoch:38,  Loss: tensor([772.9999]), max_steps: 149.7\n",
      "epoch:39,  Loss: tensor([740.1431]), max_steps: 174.3\n",
      "epoch:40,  Loss: tensor([783.9193]), max_steps: 156.7\n",
      "epoch:41,  Loss: tensor([809.8714]), max_steps: 155.6\n",
      "epoch:42,  Loss: tensor([756.0452]), max_steps: 129.1\n",
      "epoch:43,  Loss: tensor([810.2118]), max_steps: 146.8\n",
      "epoch:44,  Loss: tensor([737.1626]), max_steps: 163.5\n",
      "epoch:45,  Loss: tensor([736.4918]), max_steps: 184.6\n",
      "epoch:46,  Loss: tensor([871.4568]), max_steps: 146.2\n",
      "epoch:47,  Loss: tensor([819.4266]), max_steps: 192.4\n",
      "epoch:48,  Loss: tensor([782.1318]), max_steps: 181.9\n",
      "epoch:49,  Loss: tensor([866.1854]), max_steps: 179.9\n",
      "epoch:50,  Loss: tensor([937.5143]), max_steps: 199.1\n",
      "epoch:51,  Loss: tensor([885.6986]), max_steps: 185.4\n",
      "epoch:52,  Loss: tensor([878.8904]), max_steps: 189.2\n",
      "epoch:53,  Loss: tensor([874.5104]), max_steps: 200.0\n",
      "epoch:54,  Loss: tensor([905.7106]), max_steps: 198.1\n",
      "epoch:55,  Loss: tensor([903.6960]), max_steps: 187.2\n",
      "epoch:56,  Loss: tensor([848.2377]), max_steps: 200.0\n",
      "epoch:57,  Loss: tensor([903.4448]), max_steps: 193.2\n",
      "epoch:58,  Loss: tensor([862.6551]), max_steps: 200.0\n",
      "epoch:59,  Loss: tensor([889.7209]), max_steps: 200.0\n",
      "epoch:60,  Loss: tensor([842.6351]), max_steps: 187.6\n",
      "epoch:61,  Loss: tensor([803.3130]), max_steps: 183.0\n",
      "epoch:62,  Loss: tensor([838.3556]), max_steps: 184.7\n",
      "epoch:63,  Loss: tensor([813.4576]), max_steps: 184.8\n",
      "epoch:64,  Loss: tensor([854.3286]), max_steps: 192.0\n",
      "epoch:65,  Loss: tensor([887.3652]), max_steps: 172.5\n",
      "epoch:66,  Loss: tensor([810.0758]), max_steps: 191.2\n",
      "epoch:67,  Loss: tensor([815.3685]), max_steps: 200.0\n",
      "epoch:68,  Loss: tensor([851.7783]), max_steps: 180.5\n",
      "epoch:69,  Loss: tensor([818.7489]), max_steps: 180.4\n",
      "epoch:70,  Loss: tensor([862.2342]), max_steps: 183.2\n",
      "epoch:71,  Loss: tensor([848.8895]), max_steps: 200.0\n",
      "epoch:72,  Loss: tensor([819.0237]), max_steps: 169.8\n",
      "epoch:73,  Loss: tensor([833.6622]), max_steps: 188.4\n",
      "epoch:74,  Loss: tensor([756.3087]), max_steps: 182.5\n",
      "epoch:75,  Loss: tensor([808.7324]), max_steps: 174.1\n",
      "epoch:76,  Loss: tensor([856.7497]), max_steps: 179.5\n",
      "epoch:77,  Loss: tensor([840.0316]), max_steps: 165.8\n",
      "epoch:78,  Loss: tensor([762.9825]), max_steps: 165.4\n",
      "epoch:79,  Loss: tensor([686.0590]), max_steps: 169.2\n",
      "epoch:80,  Loss: tensor([747.0885]), max_steps: 149.6\n",
      "epoch:81,  Loss: tensor([645.3369]), max_steps: 156.3\n",
      "epoch:82,  Loss: tensor([737.4584]), max_steps: 162.2\n",
      "epoch:83,  Loss: tensor([687.9063]), max_steps: 160.6\n",
      "epoch:84,  Loss: tensor([723.6537]), max_steps: 153.2\n",
      "epoch:85,  Loss: tensor([740.9255]), max_steps: 147.1\n",
      "epoch:86,  Loss: tensor([588.9753]), max_steps: 132.6\n",
      "epoch:87,  Loss: tensor([628.7399]), max_steps: 146.1\n",
      "epoch:88,  Loss: tensor([683.9189]), max_steps: 144.7\n",
      "epoch:89,  Loss: tensor([639.1754]), max_steps: 120.1\n",
      "epoch:90,  Loss: tensor([593.3097]), max_steps: 138.3\n",
      "epoch:91,  Loss: tensor([665.1034]), max_steps: 147.7\n",
      "epoch:92,  Loss: tensor([580.3528]), max_steps: 107.6\n",
      "epoch:93,  Loss: tensor([556.8650]), max_steps: 132.6\n",
      "epoch:94,  Loss: tensor([523.7772]), max_steps: 108.3\n",
      "epoch:95,  Loss: tensor([540.5077]), max_steps: 122.5\n",
      "epoch:96,  Loss: tensor([489.6162]), max_steps: 92.6\n",
      "epoch:97,  Loss: tensor([439.2668]), max_steps: 119.8\n",
      "epoch:98,  Loss: tensor([480.0221]), max_steps: 102.0\n",
      "epoch:99,  Loss: tensor([486.7643]), max_steps: 103.8\n",
      "epoch:100,  Loss: tensor([451.3413]), max_steps: 112.5\n",
      "epoch:101,  Loss: tensor([475.9485]), max_steps: 109.9\n",
      "epoch:102,  Loss: tensor([455.4246]), max_steps: 110.5\n",
      "epoch:103,  Loss: tensor([446.9510]), max_steps: 91.9\n",
      "epoch:104,  Loss: tensor([433.3217]), max_steps: 112.0\n",
      "epoch:105,  Loss: tensor([450.4135]), max_steps: 100.0\n",
      "epoch:106,  Loss: tensor([489.8216]), max_steps: 123.1\n",
      "epoch:107,  Loss: tensor([470.9797]), max_steps: 119.4\n",
      "epoch:108,  Loss: tensor([542.4764]), max_steps: 130.8\n",
      "epoch:109,  Loss: tensor([573.1136]), max_steps: 144.8\n",
      "epoch:110,  Loss: tensor([623.0409]), max_steps: 156.7\n",
      "epoch:111,  Loss: tensor([694.3174]), max_steps: 168.0\n",
      "epoch:112,  Loss: tensor([728.4795]), max_steps: 181.7\n",
      "epoch:113,  Loss: tensor([805.9274]), max_steps: 195.8\n",
      "epoch:114,  Loss: tensor([881.6385]), max_steps: 199.9\n",
      "epoch:115,  Loss: tensor([884.0630]), max_steps: 200.0\n",
      "epoch:116,  Loss: tensor([895.2313]), max_steps: 200.0\n",
      "epoch:117,  Loss: tensor([898.9222]), max_steps: 200.0\n",
      "epoch:118,  Loss: tensor([899.1291]), max_steps: 200.0\n",
      "epoch:119,  Loss: tensor([876.2216]), max_steps: 200.0\n",
      "epoch:120,  Loss: tensor([880.6615]), max_steps: 200.0\n",
      "epoch:121,  Loss: tensor([904.6483]), max_steps: 199.4\n",
      "epoch:122,  Loss: tensor([893.7757]), max_steps: 200.0\n",
      "epoch:123,  Loss: tensor([900.3285]), max_steps: 200.0\n",
      "epoch:124,  Loss: tensor([887.2673]), max_steps: 199.8\n",
      "epoch:125,  Loss: tensor([899.6927]), max_steps: 200.0\n",
      "epoch:126,  Loss: tensor([877.1855]), max_steps: 200.0\n",
      "epoch:127,  Loss: tensor([891.3511]), max_steps: 200.0\n",
      "epoch:128,  Loss: tensor([890.6385]), max_steps: 200.0\n",
      "epoch:129,  Loss: tensor([908.0174]), max_steps: 200.0\n",
      "epoch:130,  Loss: tensor([906.5628]), max_steps: 200.0\n",
      "epoch:131,  Loss: tensor([897.5749]), max_steps: 200.0\n",
      "epoch:132,  Loss: tensor([892.3887]), max_steps: 200.0\n",
      "epoch:133,  Loss: tensor([898.2018]), max_steps: 200.0\n",
      "epoch:134,  Loss: tensor([902.0763]), max_steps: 200.0\n",
      "epoch:135,  Loss: tensor([895.6872]), max_steps: 200.0\n",
      "epoch:136,  Loss: tensor([901.6943]), max_steps: 200.0\n",
      "epoch:137,  Loss: tensor([922.1154]), max_steps: 200.0\n",
      "epoch:138,  Loss: tensor([918.3880]), max_steps: 200.0\n",
      "epoch:139,  Loss: tensor([916.7573]), max_steps: 200.0\n",
      "epoch:140,  Loss: tensor([921.0414]), max_steps: 200.0\n",
      "epoch:141,  Loss: tensor([917.6717]), max_steps: 200.0\n",
      "epoch:142,  Loss: tensor([918.2646]), max_steps: 200.0\n",
      "epoch:143,  Loss: tensor([922.3445]), max_steps: 200.0\n",
      "epoch:144,  Loss: tensor([923.4116]), max_steps: 200.0\n",
      "epoch:145,  Loss: tensor([938.4128]), max_steps: 200.0\n",
      "epoch:146,  Loss: tensor([928.3990]), max_steps: 200.0\n",
      "epoch:147,  Loss: tensor([934.7133]), max_steps: 200.0\n",
      "epoch:148,  Loss: tensor([936.5770]), max_steps: 200.0\n",
      "epoch:149,  Loss: tensor([941.9877]), max_steps: 200.0\n",
      "epoch:150,  Loss: tensor([946.0695]), max_steps: 199.2\n",
      "epoch:151,  Loss: tensor([930.4348]), max_steps: 195.3\n",
      "epoch:152,  Loss: tensor([921.7318]), max_steps: 189.4\n",
      "epoch:153,  Loss: tensor([884.0988]), max_steps: 185.3\n",
      "epoch:154,  Loss: tensor([821.7050]), max_steps: 172.3\n",
      "epoch:155,  Loss: tensor([835.7811]), max_steps: 168.3\n",
      "epoch:156,  Loss: tensor([788.9415]), max_steps: 162.2\n",
      "epoch:157,  Loss: tensor([759.1768]), max_steps: 166.1\n",
      "epoch:158,  Loss: tensor([747.1262]), max_steps: 171.5\n",
      "epoch:159,  Loss: tensor([781.6744]), max_steps: 175.9\n",
      "epoch:160,  Loss: tensor([829.3018]), max_steps: 181.8\n",
      "epoch:161,  Loss: tensor([841.2085]), max_steps: 186.9\n",
      "epoch:162,  Loss: tensor([873.7489]), max_steps: 193.2\n",
      "epoch:163,  Loss: tensor([908.2684]), max_steps: 196.3\n",
      "epoch:164,  Loss: tensor([911.9927]), max_steps: 196.5\n",
      "epoch:165,  Loss: tensor([934.8485]), max_steps: 195.3\n",
      "epoch:166,  Loss: tensor([929.8387]), max_steps: 196.1\n",
      "epoch:167,  Loss: tensor([941.3993]), max_steps: 198.9\n",
      "epoch:168,  Loss: tensor([950.8560]), max_steps: 200.0\n",
      "epoch:169,  Loss: tensor([946.3332]), max_steps: 200.0\n",
      "epoch:170,  Loss: tensor([958.5664]), max_steps: 200.0\n",
      "epoch:171,  Loss: tensor([953.7007]), max_steps: 199.3\n",
      "epoch:172,  Loss: tensor([955.6918]), max_steps: 200.0\n",
      "epoch:173,  Loss: tensor([955.5184]), max_steps: 200.0\n",
      "epoch:174,  Loss: tensor([960.8557]), max_steps: 200.0\n",
      "epoch:175,  Loss: tensor([959.3903]), max_steps: 200.0\n",
      "epoch:176,  Loss: tensor([962.5210]), max_steps: 200.0\n",
      "epoch:177,  Loss: tensor([963.8919]), max_steps: 200.0\n",
      "epoch:178,  Loss: tensor([953.3353]), max_steps: 200.0\n",
      "epoch:179,  Loss: tensor([948.5467]), max_steps: 200.0\n",
      "epoch:180,  Loss: tensor([960.7672]), max_steps: 200.0\n",
      "epoch:181,  Loss: tensor([958.5737]), max_steps: 200.0\n",
      "epoch:182,  Loss: tensor([948.9911]), max_steps: 200.0\n",
      "epoch:183,  Loss: tensor([951.1364]), max_steps: 200.0\n",
      "epoch:184,  Loss: tensor([948.7803]), max_steps: 200.0\n",
      "epoch:185,  Loss: tensor([937.1523]), max_steps: 200.0\n",
      "epoch:186,  Loss: tensor([935.9369]), max_steps: 200.0\n",
      "epoch:187,  Loss: tensor([936.2445]), max_steps: 200.0\n",
      "epoch:188,  Loss: tensor([913.3390]), max_steps: 200.0\n",
      "epoch:189,  Loss: tensor([920.6021]), max_steps: 200.0\n",
      "epoch:190,  Loss: tensor([908.2052]), max_steps: 200.0\n",
      "epoch:191,  Loss: tensor([900.5074]), max_steps: 200.0\n",
      "epoch:192,  Loss: tensor([896.3353]), max_steps: 200.0\n",
      "epoch:193,  Loss: tensor([892.1227]), max_steps: 200.0\n",
      "epoch:194,  Loss: tensor([902.3794]), max_steps: 200.0\n",
      "epoch:195,  Loss: tensor([890.3216]), max_steps: 200.0\n",
      "epoch:196,  Loss: tensor([901.7565]), max_steps: 200.0\n",
      "epoch:197,  Loss: tensor([904.6027]), max_steps: 200.0\n",
      "epoch:198,  Loss: tensor([899.7951]), max_steps: 200.0\n",
      "epoch:199,  Loss: tensor([900.2991]), max_steps: 200.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 20\n",
    "gamma = 0.9\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch = generate_episode(env, batch_size, net)\n",
    "    l = loss(batch, gamma)\n",
    "\n",
    "    # 反向传播\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "\n",
    "    writer.add_scalars(\n",
    "        \"Loss\",\n",
    "        {\"loss\": l.item(), \"max_steps\": generate_episode(env, 10, net, predict=True)},\n",
    "        epoch,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"epoch:{},  Loss: {}, max_steps: {}\".format(\n",
    "            epoch, l.detach(), generate_episode(env, 10, net, predict=True)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e098ed-1cf2-4bff-88ac-3f06d7d2f167",
   "metadata": {},
   "source": [
    "## entropy bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefd14e4-858e-4cb9-a8cf-6e34deb14f64",
   "metadata": {},
   "source": [
    "即使将策略表示为概率分布，智能体也很有可能会收敛到某些局\r\n",
    "部最优策略并停止探索环境。在DQN中，我们使用ε-greedy动作选择\r\n",
    "方式解决了这一问题：有epsilon的概率，智能体执行随机动作，而不\r\n",
    "是当前策略决定的动作。当然，我们可以使用相同的方法，但是策略\r\n",
    "梯度方法使我们可以采取更好的方法，即熵奖励（entropy bonus）。\r\n",
    "\r\n",
    "在信息论中，熵是某些系统中不确定性的度量。将熵应用到智能\r\n",
    "体的策略中，它可以显示智能体对执行何种动作的不确定程度。策略\r\n",
    "的熵可以用数学符号定义为：H(π) = –∑π(a|s)logπ(a|s)。熵的\r\n",
    "值始终大于零，并且在策略符合平均分布（换句话说，所有动作具有\r\n",
    "相同的概率）时具有一个最大值。当策略决定某个动作的概率为1而所\r\n",
    "有其他动作的概率为0时，熵就变得最小，这意味着该智能体完全确定\r\n",
    "要做什么。为了防止智能体陷入局部最小值，在损失函数中减去熵，\r\n",
    "以惩罚智能体过于确定要采取的动作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8068c9-8094-4c17-8e6b-ffc5512e023d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(batch, gamma, entropy_beta):\n",
    "    l = 0\n",
    "    for episode in batch.values():\n",
    "        reward_list = [\n",
    "            reward for state, action, next_state, reward, terminated in episode\n",
    "        ]\n",
    "        state = [state for state, action, next_state, reward, terminated in episode]\n",
    "        action = [action for state, action, next_state, reward, terminated in episode]\n",
    "        qt = calculate_t_discount_reward(reward_list, gamma)\n",
    "        pi = net(torch.Tensor(state))\n",
    "        entropy_loss = -torch.sum((pi* torch.log(pi)),axis=1).mean() * entropy_beta\n",
    "        pi = pi.gather(dim=1, index=torch.LongTensor(action).reshape(-1, 1))\n",
    "        l_policy = -torch.Tensor(qt) @ torch.log(pi)\n",
    "        l += l_policy - entropy_loss\n",
    "    return l / len(batch.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa74ffa6-8efd-415b-865d-9ab2a3ada6f8",
   "metadata": {},
   "source": [
    "## entropy bonus训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94a1cf52-d35e-40e3-9d09-40ff75803c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 初始化环境\n",
    "env = gym.make(\"CartPole-v1\", max_episode_steps=200)\n",
    "# env = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "obs_n = env.observation_space.shape[0]\n",
    "hidden_num = 64\n",
    "act_n = env.action_space.n\n",
    "net = PolicyNet(obs_n, hidden_num, act_n)\n",
    "\n",
    "# 定义优化器\n",
    "opt = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# 记录\n",
    "writer = SummaryWriter(\n",
    "    log_dir=\"logs/PolicyGradient/reinforce-entropy-bonus\", comment=\"test1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a637a927-cbf5-4780-8dd4-5d99ea6705ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,  Loss: tensor([121.6083]), max_steps: 27.6\n",
      "epoch:1,  Loss: tensor([186.1725]), max_steps: 38.7\n",
      "epoch:2,  Loss: tensor([193.4650]), max_steps: 41.4\n",
      "epoch:3,  Loss: tensor([156.9653]), max_steps: 26.2\n",
      "epoch:4,  Loss: tensor([275.4433]), max_steps: 47.6\n",
      "epoch:5,  Loss: tensor([195.5026]), max_steps: 40.6\n",
      "epoch:6,  Loss: tensor([246.6728]), max_steps: 36.0\n",
      "epoch:7,  Loss: tensor([183.4123]), max_steps: 40.8\n",
      "epoch:8,  Loss: tensor([247.6472]), max_steps: 51.5\n",
      "epoch:9,  Loss: tensor([212.2267]), max_steps: 67.8\n",
      "epoch:10,  Loss: tensor([222.9993]), max_steps: 58.3\n",
      "epoch:11,  Loss: tensor([367.2082]), max_steps: 63.4\n",
      "epoch:12,  Loss: tensor([265.2997]), max_steps: 74.0\n",
      "epoch:13,  Loss: tensor([294.9002]), max_steps: 72.0\n",
      "epoch:14,  Loss: tensor([305.4070]), max_steps: 53.2\n",
      "epoch:15,  Loss: tensor([348.8931]), max_steps: 47.7\n",
      "epoch:16,  Loss: tensor([252.6658]), max_steps: 55.5\n",
      "epoch:17,  Loss: tensor([299.4608]), max_steps: 46.8\n",
      "epoch:18,  Loss: tensor([304.1024]), max_steps: 101.2\n",
      "epoch:19,  Loss: tensor([403.9759]), max_steps: 82.9\n",
      "epoch:20,  Loss: tensor([468.1169]), max_steps: 78.8\n",
      "epoch:21,  Loss: tensor([557.4446]), max_steps: 100.2\n",
      "epoch:22,  Loss: tensor([563.4360]), max_steps: 141.7\n",
      "epoch:23,  Loss: tensor([665.4882]), max_steps: 120.2\n",
      "epoch:24,  Loss: tensor([817.0301]), max_steps: 178.4\n",
      "epoch:25,  Loss: tensor([870.0931]), max_steps: 181.6\n",
      "epoch:26,  Loss: tensor([821.0912]), max_steps: 172.0\n",
      "epoch:27,  Loss: tensor([858.3746]), max_steps: 173.8\n",
      "epoch:28,  Loss: tensor([891.1476]), max_steps: 169.9\n",
      "epoch:29,  Loss: tensor([924.6908]), max_steps: 179.0\n",
      "epoch:30,  Loss: tensor([884.4567]), max_steps: 162.1\n",
      "epoch:31,  Loss: tensor([861.6761]), max_steps: 171.0\n",
      "epoch:32,  Loss: tensor([853.5023]), max_steps: 195.2\n",
      "epoch:33,  Loss: tensor([884.0884]), max_steps: 175.3\n",
      "epoch:34,  Loss: tensor([999.4466]), max_steps: 180.3\n",
      "epoch:35,  Loss: tensor([937.8893]), max_steps: 167.8\n",
      "epoch:36,  Loss: tensor([979.9985]), max_steps: 188.2\n",
      "epoch:37,  Loss: tensor([999.6652]), max_steps: 172.5\n",
      "epoch:38,  Loss: tensor([997.8496]), max_steps: 195.3\n",
      "epoch:39,  Loss: tensor([1015.9067]), max_steps: 181.1\n",
      "epoch:40,  Loss: tensor([966.7443]), max_steps: 195.3\n",
      "epoch:41,  Loss: tensor([985.3500]), max_steps: 184.4\n",
      "epoch:42,  Loss: tensor([912.7802]), max_steps: 189.0\n",
      "epoch:43,  Loss: tensor([1015.0515]), max_steps: 191.0\n",
      "epoch:44,  Loss: tensor([1025.9148]), max_steps: 183.7\n",
      "epoch:45,  Loss: tensor([890.3661]), max_steps: 177.1\n",
      "epoch:46,  Loss: tensor([846.2140]), max_steps: 151.4\n",
      "epoch:47,  Loss: tensor([776.4109]), max_steps: 138.5\n",
      "epoch:48,  Loss: tensor([761.9820]), max_steps: 156.7\n",
      "epoch:49,  Loss: tensor([694.6293]), max_steps: 131.1\n",
      "epoch:50,  Loss: tensor([700.3890]), max_steps: 152.7\n",
      "epoch:51,  Loss: tensor([687.2577]), max_steps: 150.6\n",
      "epoch:52,  Loss: tensor([781.1283]), max_steps: 153.0\n",
      "epoch:53,  Loss: tensor([747.4298]), max_steps: 142.6\n",
      "epoch:54,  Loss: tensor([756.8889]), max_steps: 152.4\n",
      "epoch:55,  Loss: tensor([799.3738]), max_steps: 144.7\n",
      "epoch:56,  Loss: tensor([799.7531]), max_steps: 156.4\n",
      "epoch:57,  Loss: tensor([799.4872]), max_steps: 162.1\n",
      "epoch:58,  Loss: tensor([830.9484]), max_steps: 179.2\n",
      "epoch:59,  Loss: tensor([889.2988]), max_steps: 185.9\n",
      "epoch:60,  Loss: tensor([977.9494]), max_steps: 183.1\n",
      "epoch:61,  Loss: tensor([988.9134]), max_steps: 191.4\n",
      "epoch:62,  Loss: tensor([989.0500]), max_steps: 200.0\n",
      "epoch:63,  Loss: tensor([1030.6578]), max_steps: 196.0\n",
      "epoch:64,  Loss: tensor([1034.0623]), max_steps: 200.0\n",
      "epoch:65,  Loss: tensor([1012.3864]), max_steps: 199.7\n",
      "epoch:66,  Loss: tensor([1016.4117]), max_steps: 198.6\n",
      "epoch:67,  Loss: tensor([1014.6082]), max_steps: 194.8\n",
      "epoch:68,  Loss: tensor([986.4533]), max_steps: 186.5\n",
      "epoch:69,  Loss: tensor([897.7778]), max_steps: 166.9\n",
      "epoch:70,  Loss: tensor([811.8989]), max_steps: 136.9\n",
      "epoch:71,  Loss: tensor([716.0223]), max_steps: 122.0\n",
      "epoch:72,  Loss: tensor([549.6459]), max_steps: 134.4\n",
      "epoch:73,  Loss: tensor([541.4089]), max_steps: 111.1\n",
      "epoch:74,  Loss: tensor([541.2577]), max_steps: 104.7\n",
      "epoch:75,  Loss: tensor([559.0983]), max_steps: 109.5\n",
      "epoch:76,  Loss: tensor([496.9438]), max_steps: 119.0\n",
      "epoch:77,  Loss: tensor([468.9902]), max_steps: 106.6\n",
      "epoch:78,  Loss: tensor([505.2686]), max_steps: 110.6\n",
      "epoch:79,  Loss: tensor([502.9984]), max_steps: 109.5\n",
      "epoch:80,  Loss: tensor([538.5557]), max_steps: 108.2\n",
      "epoch:81,  Loss: tensor([530.7990]), max_steps: 112.2\n",
      "epoch:82,  Loss: tensor([525.7287]), max_steps: 106.7\n",
      "epoch:83,  Loss: tensor([612.9534]), max_steps: 123.8\n",
      "epoch:84,  Loss: tensor([569.6399]), max_steps: 132.5\n",
      "epoch:85,  Loss: tensor([637.6460]), max_steps: 130.8\n",
      "epoch:86,  Loss: tensor([633.1756]), max_steps: 131.9\n",
      "epoch:87,  Loss: tensor([639.4609]), max_steps: 126.7\n",
      "epoch:88,  Loss: tensor([685.7893]), max_steps: 129.8\n",
      "epoch:89,  Loss: tensor([675.1913]), max_steps: 128.6\n",
      "epoch:90,  Loss: tensor([716.0900]), max_steps: 144.4\n",
      "epoch:91,  Loss: tensor([731.6178]), max_steps: 145.5\n",
      "epoch:92,  Loss: tensor([669.0099]), max_steps: 154.3\n",
      "epoch:93,  Loss: tensor([765.9367]), max_steps: 147.2\n",
      "epoch:94,  Loss: tensor([748.9507]), max_steps: 115.9\n",
      "epoch:95,  Loss: tensor([732.2207]), max_steps: 138.8\n",
      "epoch:96,  Loss: tensor([639.1576]), max_steps: 131.5\n",
      "epoch:97,  Loss: tensor([692.9430]), max_steps: 136.8\n",
      "epoch:98,  Loss: tensor([665.7357]), max_steps: 131.7\n",
      "epoch:99,  Loss: tensor([624.4196]), max_steps: 129.1\n",
      "epoch:100,  Loss: tensor([676.9046]), max_steps: 125.5\n",
      "epoch:101,  Loss: tensor([667.5507]), max_steps: 133.6\n",
      "epoch:102,  Loss: tensor([663.5198]), max_steps: 134.1\n",
      "epoch:103,  Loss: tensor([716.6335]), max_steps: 135.1\n",
      "epoch:104,  Loss: tensor([718.3370]), max_steps: 141.6\n",
      "epoch:105,  Loss: tensor([723.6270]), max_steps: 138.4\n",
      "epoch:106,  Loss: tensor([704.7639]), max_steps: 148.5\n",
      "epoch:107,  Loss: tensor([759.8984]), max_steps: 164.0\n",
      "epoch:108,  Loss: tensor([813.3275]), max_steps: 161.0\n",
      "epoch:109,  Loss: tensor([805.5643]), max_steps: 162.5\n",
      "epoch:110,  Loss: tensor([825.6713]), max_steps: 155.4\n",
      "epoch:111,  Loss: tensor([864.6940]), max_steps: 167.9\n",
      "epoch:112,  Loss: tensor([905.1993]), max_steps: 185.0\n",
      "epoch:113,  Loss: tensor([935.8107]), max_steps: 182.4\n",
      "epoch:114,  Loss: tensor([975.7546]), max_steps: 194.0\n",
      "epoch:115,  Loss: tensor([1024.7865]), max_steps: 200.0\n",
      "epoch:116,  Loss: tensor([1025.6523]), max_steps: 200.0\n",
      "epoch:117,  Loss: tensor([1032.9010]), max_steps: 200.0\n",
      "epoch:118,  Loss: tensor([1034.1742]), max_steps: 200.0\n",
      "epoch:119,  Loss: tensor([1047.7312]), max_steps: 199.6\n",
      "epoch:120,  Loss: tensor([1045.7542]), max_steps: 200.0\n",
      "epoch:121,  Loss: tensor([1056.9756]), max_steps: 200.0\n",
      "epoch:122,  Loss: tensor([1027.3025]), max_steps: 200.0\n",
      "epoch:123,  Loss: tensor([1038.8243]), max_steps: 200.0\n",
      "epoch:124,  Loss: tensor([1042.8119]), max_steps: 200.0\n",
      "epoch:125,  Loss: tensor([1040.1355]), max_steps: 200.0\n",
      "epoch:126,  Loss: tensor([1032.8943]), max_steps: 200.0\n",
      "epoch:127,  Loss: tensor([1033.8340]), max_steps: 200.0\n",
      "epoch:128,  Loss: tensor([1024.4537]), max_steps: 200.0\n",
      "epoch:129,  Loss: tensor([1056.5494]), max_steps: 197.6\n",
      "epoch:130,  Loss: tensor([1029.4232]), max_steps: 197.2\n",
      "epoch:131,  Loss: tensor([1020.6256]), max_steps: 199.1\n",
      "epoch:132,  Loss: tensor([1029.8881]), max_steps: 194.7\n",
      "epoch:133,  Loss: tensor([1037.5874]), max_steps: 191.6\n",
      "epoch:134,  Loss: tensor([1020.8661]), max_steps: 192.2\n",
      "epoch:135,  Loss: tensor([1002.8157]), max_steps: 190.8\n",
      "epoch:136,  Loss: tensor([1046.2419]), max_steps: 196.7\n",
      "epoch:137,  Loss: tensor([1050.9722]), max_steps: 199.0\n",
      "epoch:138,  Loss: tensor([1066.2609]), max_steps: 199.2\n",
      "epoch:139,  Loss: tensor([1059.3672]), max_steps: 200.0\n",
      "epoch:140,  Loss: tensor([1081.8657]), max_steps: 200.0\n",
      "epoch:141,  Loss: tensor([1088.7770]), max_steps: 200.0\n",
      "epoch:142,  Loss: tensor([1082.9695]), max_steps: 200.0\n",
      "epoch:143,  Loss: tensor([1085.7223]), max_steps: 200.0\n",
      "epoch:144,  Loss: tensor([1082.5980]), max_steps: 198.2\n",
      "epoch:145,  Loss: tensor([1078.5959]), max_steps: 196.4\n",
      "epoch:146,  Loss: tensor([1078.5518]), max_steps: 198.9\n",
      "epoch:147,  Loss: tensor([1039.2375]), max_steps: 199.1\n",
      "epoch:148,  Loss: tensor([1099.0367]), max_steps: 181.9\n",
      "epoch:149,  Loss: tensor([1036.2805]), max_steps: 199.3\n",
      "epoch:150,  Loss: tensor([970.2096]), max_steps: 116.6\n",
      "epoch:151,  Loss: tensor([815.9606]), max_steps: 179.3\n",
      "epoch:152,  Loss: tensor([838.0804]), max_steps: 101.3\n",
      "epoch:153,  Loss: tensor([768.0184]), max_steps: 134.1\n",
      "epoch:154,  Loss: tensor([471.7634]), max_steps: 64.6\n",
      "epoch:155,  Loss: tensor([415.9128]), max_steps: 75.0\n",
      "epoch:156,  Loss: tensor([445.7994]), max_steps: 82.2\n",
      "epoch:157,  Loss: tensor([332.7640]), max_steps: 90.8\n",
      "epoch:158,  Loss: tensor([514.2586]), max_steps: 71.4\n",
      "epoch:159,  Loss: tensor([480.8683]), max_steps: 140.4\n",
      "epoch:160,  Loss: tensor([604.7184]), max_steps: 145.7\n",
      "epoch:161,  Loss: tensor([772.4247]), max_steps: 168.4\n",
      "epoch:162,  Loss: tensor([905.9449]), max_steps: 138.4\n",
      "epoch:163,  Loss: tensor([1056.2198]), max_steps: 200.0\n",
      "epoch:164,  Loss: tensor([1047.8877]), max_steps: 187.0\n",
      "epoch:165,  Loss: tensor([1033.6740]), max_steps: 197.0\n",
      "epoch:166,  Loss: tensor([988.7959]), max_steps: 200.0\n",
      "epoch:167,  Loss: tensor([1090.4480]), max_steps: 200.0\n",
      "epoch:168,  Loss: tensor([1097.4202]), max_steps: 200.0\n",
      "epoch:169,  Loss: tensor([1077.5690]), max_steps: 200.0\n",
      "epoch:170,  Loss: tensor([1060.9602]), max_steps: 200.0\n",
      "epoch:171,  Loss: tensor([1089.5471]), max_steps: 200.0\n",
      "epoch:172,  Loss: tensor([1093.4434]), max_steps: 200.0\n",
      "epoch:173,  Loss: tensor([1096.9653]), max_steps: 200.0\n",
      "epoch:174,  Loss: tensor([1097.2094]), max_steps: 200.0\n",
      "epoch:175,  Loss: tensor([1094.9994]), max_steps: 200.0\n",
      "epoch:176,  Loss: tensor([1090.5051]), max_steps: 200.0\n",
      "epoch:177,  Loss: tensor([1097.2429]), max_steps: 200.0\n",
      "epoch:178,  Loss: tensor([1095.7428]), max_steps: 200.0\n",
      "epoch:179,  Loss: tensor([1091.1039]), max_steps: 200.0\n",
      "epoch:180,  Loss: tensor([1093.8899]), max_steps: 200.0\n",
      "epoch:181,  Loss: tensor([1101.5219]), max_steps: 200.0\n",
      "epoch:182,  Loss: tensor([1086.2437]), max_steps: 200.0\n",
      "epoch:183,  Loss: tensor([1092.8531]), max_steps: 200.0\n",
      "epoch:184,  Loss: tensor([1083.5219]), max_steps: 194.0\n",
      "epoch:185,  Loss: tensor([1076.1738]), max_steps: 176.3\n",
      "epoch:186,  Loss: tensor([999.7967]), max_steps: 169.2\n",
      "epoch:187,  Loss: tensor([825.1852]), max_steps: 131.6\n",
      "epoch:188,  Loss: tensor([788.4166]), max_steps: 140.3\n",
      "epoch:189,  Loss: tensor([727.8365]), max_steps: 120.2\n",
      "epoch:190,  Loss: tensor([636.9870]), max_steps: 115.2\n",
      "epoch:191,  Loss: tensor([575.1610]), max_steps: 99.5\n",
      "epoch:192,  Loss: tensor([501.3665]), max_steps: 108.3\n",
      "epoch:193,  Loss: tensor([499.9234]), max_steps: 92.8\n",
      "epoch:194,  Loss: tensor([460.5205]), max_steps: 92.3\n",
      "epoch:195,  Loss: tensor([499.8928]), max_steps: 96.8\n",
      "epoch:196,  Loss: tensor([479.3127]), max_steps: 104.8\n",
      "epoch:197,  Loss: tensor([478.6080]), max_steps: 108.9\n",
      "epoch:198,  Loss: tensor([493.9308]), max_steps: 107.3\n",
      "epoch:199,  Loss: tensor([560.5659]), max_steps: 117.9\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 20\n",
    "gamma = 0.9\n",
    "entropy_beta= 0.01\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch = generate_episode(env, batch_size, net)\n",
    "    l = loss(batch, gamma, entropy_beta)\n",
    "\n",
    "    # 反向传播\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "\n",
    "    writer.add_scalars(\n",
    "        \"Loss\",\n",
    "        {\"loss\": l.item(), \"max_steps\": generate_episode(env, 10, net, predict=True)},\n",
    "        epoch,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"epoch:{},  Loss: {}, max_steps: {}\".format(\n",
    "            epoch, l.detach(), generate_episode(env, 10, net, predict=True)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaae2f0-b8ed-46a5-bf58-ef9752e27543",
   "metadata": {},
   "source": [
    "## entropy_beta&baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71ae24d4-05e7-469b-b376-38ddfae7d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(batch, gamma, entropy_beta=False, baseline=False):\n",
    "    l = 0\n",
    "    for episode in batch.values():\n",
    "        reward_list = [\n",
    "            reward for state, action, next_state, reward, terminated in episode\n",
    "        ]\n",
    "        state = [state for state, action, next_state, reward, terminated in episode]\n",
    "        action = [action for state, action, next_state, reward, terminated in episode]\n",
    "        qt = calculate_t_discount_reward(reward_list, gamma, baseline)\n",
    "        pi = net(torch.Tensor(state))\n",
    "        entropy_loss = -torch.sum((pi * torch.log(pi)), axis=1).mean() * entropy_beta\n",
    "        pi = pi.gather(dim=1, index=torch.LongTensor(action).reshape(-1, 1))\n",
    "        l_policy = -torch.Tensor(qt) @ torch.log(pi)\n",
    "        if entropy_beta:\n",
    "            l += l_policy - entropy_loss\n",
    "        else:\n",
    "            l += l_policy\n",
    "    return l / len(batch.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc41af04-f264-46e5-9193-07aacf3216f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 初始化环境\n",
    "env = gym.make(\"CartPole-v1\", max_episode_steps=200)\n",
    "# env = gym.make(\"CartPole-v1\", render_mode = \"human\")\n",
    "\n",
    "state, info = env.reset()\n",
    "\n",
    "obs_n = env.observation_space.shape[0]\n",
    "hidden_num = 64\n",
    "act_n = env.action_space.n\n",
    "net = PolicyNet(obs_n, hidden_num, act_n)\n",
    "\n",
    "# 定义优化器\n",
    "opt = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# 记录\n",
    "writer = SummaryWriter(\n",
    "    log_dir=\"logs/PolicyGradient/reinforce-entropy-bonus&baseline\", comment=\"test1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac6d116f-14ac-48bf-b7dd-1086dd2071bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0,  Loss: tensor([82.1014]), max_steps: 29.7\n",
      "epoch:1,  Loss: tensor([98.1543]), max_steps: 26.5\n",
      "epoch:2,  Loss: tensor([96.1294]), max_steps: 29.7\n",
      "epoch:3,  Loss: tensor([114.7237]), max_steps: 26.6\n",
      "epoch:4,  Loss: tensor([145.7323]), max_steps: 36.7\n",
      "epoch:5,  Loss: tensor([159.2324]), max_steps: 51.4\n",
      "epoch:6,  Loss: tensor([170.9406]), max_steps: 39.4\n",
      "epoch:7,  Loss: tensor([216.6581]), max_steps: 50.6\n",
      "epoch:8,  Loss: tensor([211.0787]), max_steps: 52.1\n",
      "epoch:9,  Loss: tensor([326.0906]), max_steps: 43.6\n",
      "epoch:10,  Loss: tensor([311.7147]), max_steps: 71.7\n",
      "epoch:11,  Loss: tensor([324.1201]), max_steps: 47.7\n",
      "epoch:12,  Loss: tensor([263.7476]), max_steps: 69.8\n",
      "epoch:13,  Loss: tensor([298.4491]), max_steps: 73.9\n",
      "epoch:14,  Loss: tensor([362.7023]), max_steps: 78.4\n",
      "epoch:15,  Loss: tensor([352.8200]), max_steps: 87.1\n",
      "epoch:16,  Loss: tensor([413.0023]), max_steps: 100.4\n",
      "epoch:17,  Loss: tensor([463.8265]), max_steps: 104.3\n",
      "epoch:18,  Loss: tensor([552.8887]), max_steps: 113.7\n",
      "epoch:19,  Loss: tensor([601.4865]), max_steps: 162.9\n",
      "epoch:20,  Loss: tensor([698.6029]), max_steps: 172.3\n",
      "epoch:21,  Loss: tensor([732.2483]), max_steps: 165.4\n",
      "epoch:22,  Loss: tensor([754.5959]), max_steps: 182.9\n",
      "epoch:23,  Loss: tensor([795.7435]), max_steps: 177.0\n",
      "epoch:24,  Loss: tensor([811.1009]), max_steps: 185.2\n",
      "epoch:25,  Loss: tensor([855.7250]), max_steps: 195.6\n",
      "epoch:26,  Loss: tensor([866.2699]), max_steps: 198.0\n",
      "epoch:27,  Loss: tensor([878.7489]), max_steps: 194.5\n",
      "epoch:28,  Loss: tensor([920.0378]), max_steps: 181.4\n",
      "epoch:29,  Loss: tensor([857.4689]), max_steps: 184.1\n",
      "epoch:30,  Loss: tensor([872.4888]), max_steps: 187.7\n",
      "epoch:31,  Loss: tensor([929.9042]), max_steps: 185.3\n",
      "epoch:32,  Loss: tensor([919.5300]), max_steps: 198.1\n",
      "epoch:33,  Loss: tensor([948.4632]), max_steps: 194.3\n",
      "epoch:34,  Loss: tensor([947.2736]), max_steps: 198.0\n",
      "epoch:35,  Loss: tensor([925.1722]), max_steps: 189.5\n",
      "epoch:36,  Loss: tensor([840.9577]), max_steps: 189.2\n",
      "epoch:37,  Loss: tensor([935.0294]), max_steps: 196.4\n",
      "epoch:38,  Loss: tensor([897.8524]), max_steps: 194.8\n",
      "epoch:39,  Loss: tensor([906.3979]), max_steps: 200.0\n",
      "epoch:40,  Loss: tensor([886.9594]), max_steps: 191.7\n",
      "epoch:41,  Loss: tensor([881.5071]), max_steps: 194.6\n",
      "epoch:42,  Loss: tensor([925.2488]), max_steps: 170.8\n",
      "epoch:43,  Loss: tensor([901.1688]), max_steps: 176.5\n",
      "epoch:44,  Loss: tensor([795.8188]), max_steps: 133.4\n",
      "epoch:45,  Loss: tensor([706.4304]), max_steps: 126.5\n",
      "epoch:46,  Loss: tensor([533.4661]), max_steps: 122.5\n",
      "epoch:47,  Loss: tensor([464.2933]), max_steps: 79.8\n",
      "epoch:48,  Loss: tensor([433.8553]), max_steps: 57.1\n",
      "epoch:49,  Loss: tensor([287.6137]), max_steps: 80.8\n",
      "epoch:50,  Loss: tensor([292.2883]), max_steps: 81.6\n",
      "epoch:51,  Loss: tensor([326.0641]), max_steps: 88.3\n",
      "epoch:52,  Loss: tensor([395.5314]), max_steps: 108.2\n",
      "epoch:53,  Loss: tensor([419.8612]), max_steps: 123.4\n",
      "epoch:54,  Loss: tensor([508.4072]), max_steps: 138.5\n",
      "epoch:55,  Loss: tensor([577.3716]), max_steps: 155.7\n",
      "epoch:56,  Loss: tensor([634.9413]), max_steps: 172.7\n",
      "epoch:57,  Loss: tensor([755.8580]), max_steps: 177.5\n",
      "epoch:58,  Loss: tensor([809.9521]), max_steps: 198.4\n",
      "epoch:59,  Loss: tensor([876.1260]), max_steps: 200.0\n",
      "epoch:60,  Loss: tensor([895.5755]), max_steps: 200.0\n",
      "epoch:61,  Loss: tensor([896.0324]), max_steps: 200.0\n",
      "epoch:62,  Loss: tensor([911.9866]), max_steps: 200.0\n",
      "epoch:63,  Loss: tensor([903.0081]), max_steps: 200.0\n",
      "epoch:64,  Loss: tensor([908.2196]), max_steps: 200.0\n",
      "epoch:65,  Loss: tensor([922.8431]), max_steps: 200.0\n",
      "epoch:66,  Loss: tensor([903.3307]), max_steps: 200.0\n",
      "epoch:67,  Loss: tensor([933.9217]), max_steps: 191.3\n",
      "epoch:68,  Loss: tensor([936.4785]), max_steps: 200.0\n",
      "epoch:69,  Loss: tensor([922.4890]), max_steps: 200.0\n",
      "epoch:70,  Loss: tensor([936.5550]), max_steps: 186.6\n",
      "epoch:71,  Loss: tensor([920.6632]), max_steps: 200.0\n",
      "epoch:72,  Loss: tensor([921.5529]), max_steps: 200.0\n",
      "epoch:73,  Loss: tensor([899.1810]), max_steps: 200.0\n",
      "epoch:74,  Loss: tensor([947.3936]), max_steps: 200.0\n",
      "epoch:75,  Loss: tensor([941.6859]), max_steps: 200.0\n",
      "epoch:76,  Loss: tensor([933.7669]), max_steps: 190.6\n",
      "epoch:77,  Loss: tensor([951.5646]), max_steps: 200.0\n",
      "epoch:78,  Loss: tensor([942.3427]), max_steps: 193.2\n",
      "epoch:79,  Loss: tensor([937.8957]), max_steps: 200.0\n",
      "epoch:80,  Loss: tensor([913.0460]), max_steps: 200.0\n",
      "epoch:81,  Loss: tensor([953.9794]), max_steps: 200.0\n",
      "epoch:82,  Loss: tensor([935.0617]), max_steps: 200.0\n",
      "epoch:83,  Loss: tensor([926.9799]), max_steps: 200.0\n",
      "epoch:84,  Loss: tensor([953.6498]), max_steps: 188.7\n",
      "epoch:85,  Loss: tensor([945.1447]), max_steps: 200.0\n",
      "epoch:86,  Loss: tensor([945.3123]), max_steps: 200.0\n",
      "epoch:87,  Loss: tensor([944.5744]), max_steps: 200.0\n",
      "epoch:88,  Loss: tensor([933.2059]), max_steps: 200.0\n",
      "epoch:89,  Loss: tensor([935.2565]), max_steps: 200.0\n",
      "epoch:90,  Loss: tensor([934.8973]), max_steps: 200.0\n",
      "epoch:91,  Loss: tensor([925.9956]), max_steps: 200.0\n",
      "epoch:92,  Loss: tensor([921.8168]), max_steps: 200.0\n",
      "epoch:93,  Loss: tensor([906.4647]), max_steps: 200.0\n",
      "epoch:94,  Loss: tensor([911.5301]), max_steps: 200.0\n",
      "epoch:95,  Loss: tensor([907.1016]), max_steps: 200.0\n",
      "epoch:96,  Loss: tensor([905.2950]), max_steps: 200.0\n",
      "epoch:97,  Loss: tensor([892.2111]), max_steps: 200.0\n",
      "epoch:98,  Loss: tensor([837.9883]), max_steps: 198.4\n",
      "epoch:99,  Loss: tensor([882.7211]), max_steps: 198.1\n",
      "epoch:100,  Loss: tensor([846.2785]), max_steps: 187.6\n",
      "epoch:101,  Loss: tensor([838.0698]), max_steps: 197.1\n",
      "epoch:102,  Loss: tensor([821.2200]), max_steps: 195.7\n",
      "epoch:103,  Loss: tensor([838.3287]), max_steps: 190.2\n",
      "epoch:104,  Loss: tensor([799.2426]), max_steps: 194.8\n",
      "epoch:105,  Loss: tensor([808.4916]), max_steps: 196.3\n",
      "epoch:106,  Loss: tensor([793.2269]), max_steps: 192.2\n",
      "epoch:107,  Loss: tensor([814.6613]), max_steps: 198.1\n",
      "epoch:108,  Loss: tensor([791.8905]), max_steps: 193.2\n",
      "epoch:109,  Loss: tensor([790.2911]), max_steps: 193.8\n",
      "epoch:110,  Loss: tensor([778.6231]), max_steps: 193.2\n",
      "epoch:111,  Loss: tensor([779.4811]), max_steps: 194.6\n",
      "epoch:112,  Loss: tensor([766.1337]), max_steps: 195.2\n",
      "epoch:113,  Loss: tensor([775.4078]), max_steps: 196.5\n",
      "epoch:114,  Loss: tensor([783.0646]), max_steps: 197.7\n",
      "epoch:115,  Loss: tensor([766.1512]), max_steps: 196.1\n",
      "epoch:116,  Loss: tensor([789.5151]), max_steps: 200.0\n",
      "epoch:117,  Loss: tensor([795.1827]), max_steps: 200.0\n",
      "epoch:118,  Loss: tensor([802.3862]), max_steps: 200.0\n",
      "epoch:119,  Loss: tensor([782.3681]), max_steps: 200.0\n",
      "epoch:120,  Loss: tensor([827.5872]), max_steps: 200.0\n",
      "epoch:121,  Loss: tensor([815.1492]), max_steps: 200.0\n",
      "epoch:122,  Loss: tensor([819.6748]), max_steps: 200.0\n",
      "epoch:123,  Loss: tensor([808.6957]), max_steps: 200.0\n",
      "epoch:124,  Loss: tensor([850.0983]), max_steps: 200.0\n",
      "epoch:125,  Loss: tensor([815.2864]), max_steps: 200.0\n",
      "epoch:126,  Loss: tensor([854.3402]), max_steps: 200.0\n",
      "epoch:127,  Loss: tensor([840.5924]), max_steps: 200.0\n",
      "epoch:128,  Loss: tensor([851.9791]), max_steps: 200.0\n",
      "epoch:129,  Loss: tensor([857.8846]), max_steps: 200.0\n",
      "epoch:130,  Loss: tensor([854.9045]), max_steps: 200.0\n",
      "epoch:131,  Loss: tensor([882.3375]), max_steps: 197.1\n",
      "epoch:132,  Loss: tensor([868.0954]), max_steps: 196.0\n",
      "epoch:133,  Loss: tensor([844.8250]), max_steps: 182.8\n",
      "epoch:134,  Loss: tensor([808.5105]), max_steps: 171.7\n",
      "epoch:135,  Loss: tensor([686.6312]), max_steps: 133.4\n",
      "epoch:136,  Loss: tensor([614.8542]), max_steps: 126.8\n",
      "epoch:137,  Loss: tensor([574.4189]), max_steps: 112.2\n",
      "epoch:138,  Loss: tensor([492.2948]), max_steps: 111.2\n",
      "epoch:139,  Loss: tensor([470.2224]), max_steps: 104.9\n",
      "epoch:140,  Loss: tensor([467.4853]), max_steps: 117.6\n",
      "epoch:141,  Loss: tensor([463.9670]), max_steps: 120.8\n",
      "epoch:142,  Loss: tensor([508.8027]), max_steps: 137.3\n",
      "epoch:143,  Loss: tensor([537.5361]), max_steps: 134.4\n",
      "epoch:144,  Loss: tensor([545.0239]), max_steps: 139.0\n",
      "epoch:145,  Loss: tensor([536.4567]), max_steps: 131.6\n",
      "epoch:146,  Loss: tensor([582.4366]), max_steps: 139.5\n",
      "epoch:147,  Loss: tensor([580.7169]), max_steps: 143.8\n",
      "epoch:148,  Loss: tensor([573.0413]), max_steps: 134.8\n",
      "epoch:149,  Loss: tensor([573.2162]), max_steps: 132.7\n",
      "epoch:150,  Loss: tensor([556.3343]), max_steps: 134.7\n",
      "epoch:151,  Loss: tensor([514.1615]), max_steps: 118.3\n",
      "epoch:152,  Loss: tensor([483.0740]), max_steps: 115.0\n",
      "epoch:153,  Loss: tensor([486.1302]), max_steps: 107.4\n",
      "epoch:154,  Loss: tensor([423.3314]), max_steps: 107.3\n",
      "epoch:155,  Loss: tensor([411.8906]), max_steps: 106.8\n",
      "epoch:156,  Loss: tensor([390.4576]), max_steps: 107.5\n",
      "epoch:157,  Loss: tensor([387.1987]), max_steps: 103.0\n",
      "epoch:158,  Loss: tensor([366.8724]), max_steps: 96.9\n",
      "epoch:159,  Loss: tensor([380.6063]), max_steps: 103.1\n",
      "epoch:160,  Loss: tensor([381.4900]), max_steps: 100.2\n",
      "epoch:161,  Loss: tensor([420.9091]), max_steps: 115.2\n",
      "epoch:162,  Loss: tensor([442.6879]), max_steps: 116.6\n",
      "epoch:163,  Loss: tensor([440.6697]), max_steps: 120.2\n",
      "epoch:164,  Loss: tensor([460.3548]), max_steps: 122.6\n",
      "epoch:165,  Loss: tensor([465.0110]), max_steps: 124.6\n",
      "epoch:166,  Loss: tensor([465.9766]), max_steps: 130.0\n",
      "epoch:167,  Loss: tensor([505.3082]), max_steps: 127.5\n",
      "epoch:168,  Loss: tensor([507.8036]), max_steps: 131.6\n",
      "epoch:169,  Loss: tensor([507.0609]), max_steps: 140.9\n",
      "epoch:170,  Loss: tensor([546.6123]), max_steps: 141.7\n",
      "epoch:171,  Loss: tensor([553.8594]), max_steps: 151.0\n",
      "epoch:172,  Loss: tensor([591.3611]), max_steps: 158.3\n",
      "epoch:173,  Loss: tensor([590.4608]), max_steps: 161.5\n",
      "epoch:174,  Loss: tensor([644.0315]), max_steps: 164.7\n",
      "epoch:175,  Loss: tensor([633.9227]), max_steps: 176.9\n",
      "epoch:176,  Loss: tensor([665.0120]), max_steps: 181.0\n",
      "epoch:177,  Loss: tensor([687.5802]), max_steps: 177.3\n",
      "epoch:178,  Loss: tensor([699.5631]), max_steps: 182.3\n",
      "epoch:179,  Loss: tensor([699.4112]), max_steps: 171.8\n",
      "epoch:180,  Loss: tensor([688.0129]), max_steps: 175.0\n",
      "epoch:181,  Loss: tensor([676.8892]), max_steps: 172.1\n",
      "epoch:182,  Loss: tensor([693.5450]), max_steps: 176.2\n",
      "epoch:183,  Loss: tensor([665.4232]), max_steps: 169.3\n",
      "epoch:184,  Loss: tensor([669.0057]), max_steps: 173.3\n",
      "epoch:185,  Loss: tensor([686.9281]), max_steps: 169.6\n",
      "epoch:186,  Loss: tensor([683.6129]), max_steps: 181.2\n",
      "epoch:187,  Loss: tensor([730.6984]), max_steps: 193.2\n",
      "epoch:188,  Loss: tensor([756.6283]), max_steps: 192.0\n",
      "epoch:189,  Loss: tensor([757.7623]), max_steps: 194.1\n",
      "epoch:190,  Loss: tensor([773.7101]), max_steps: 198.2\n",
      "epoch:191,  Loss: tensor([793.6393]), max_steps: 200.0\n",
      "epoch:192,  Loss: tensor([792.7413]), max_steps: 200.0\n",
      "epoch:193,  Loss: tensor([799.5719]), max_steps: 200.0\n",
      "epoch:194,  Loss: tensor([796.7700]), max_steps: 199.4\n",
      "epoch:195,  Loss: tensor([806.8698]), max_steps: 200.0\n",
      "epoch:196,  Loss: tensor([810.2661]), max_steps: 198.5\n",
      "epoch:197,  Loss: tensor([803.3101]), max_steps: 200.0\n",
      "epoch:198,  Loss: tensor([798.8317]), max_steps: 196.5\n",
      "epoch:199,  Loss: tensor([787.9562]), max_steps: 193.9\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 20\n",
    "gamma = 0.9\n",
    "entropy_beta= 0.01\n",
    "baseline=True\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    batch = generate_episode(env, batch_size, net)\n",
    "    l = loss(batch, gamma, entropy_beta, baseline)\n",
    "\n",
    "    # 反向传播\n",
    "    opt.zero_grad()\n",
    "    l.backward()\n",
    "    opt.step()\n",
    "\n",
    "    writer.add_scalars(\n",
    "        \"Loss\",\n",
    "        {\"loss\": l.item(), \"max_steps\": generate_episode(env, 10, net, predict=True)},\n",
    "        epoch,\n",
    "    )\n",
    "\n",
    "    print(\n",
    "        \"epoch:{},  Loss: {}, max_steps: {}\".format(\n",
    "            epoch, l.detach(), generate_episode(env, 10, net, predict=True)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429e414-f88f-4625-8016-400ca0b06e8b",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f038155-9574-478d-8f9b-1b5d3c52a4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
    "# env = gym.wrappers.RecordVideo(env, video_folder=\"video\")\n",
    "\n",
    "# state, info = env.reset()\n",
    "# total_rewards = 0\n",
    "\n",
    "# while True:\n",
    "#     p = net(torch.Tensor(state)).detach().numpy().reshape(-1)\n",
    "#     action = np.random.choice(list(range(env.action_space.n)), p=p)\n",
    "#     state, reward, terminated, truncted, info = env.step(action)\n",
    "#     if terminated:\n",
    "#         break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
