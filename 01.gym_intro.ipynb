{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81a77bee-1a0c-4302-a5a2-c28d643c5606",
   "metadata": {},
   "source": [
    "# gym\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "983fb053-da18-4b75-983f-f51df64126d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "e = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4977e506-caed-4a6b-a7f9-e4c81cb16dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.00070169, -0.04000503,  0.04951924, -0.04128506], dtype=float32),\n",
       " {})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7265f0-1267-4506-8e55-e100a764ed24",
   "metadata": {},
   "source": [
    "## 行动空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfc50f6-866c-4a71-a505-ae4280037f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c9d4e3-3006-485e-9001-22c2ebd72061",
   "metadata": {},
   "source": [
    "## 观测空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "369cea02-27ef-4104-a7b2-c68d577bfc27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.observation_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf1c41-1985-4de0-92d9-2276c24c8f9d",
   "metadata": {},
   "source": [
    "## 采取行动"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eb44963-11ba-4f7c-accd-c70e97afb056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-9.8411765e-05, -2.3580082e-01,  4.8693545e-02,  2.6660129e-01],\n",
       "       dtype=float32),\n",
       " 1.0,\n",
       " False,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.step(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ab6b16-8874-4791-a56b-666eb2eb35b7",
   "metadata": {},
   "source": [
    "## 一个训练过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5181aa-6ae8-4ef1-a3c6-1aaf2057b3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode done in 30 step， total reward 30.00\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")\n",
    "total_rewards = 0.0\n",
    "total_steps = 0\n",
    "obs = env.reset()\n",
    "\n",
    "while True:\n",
    "    action = env.action_space.sample()\n",
    "    obs, reward, terminated, truncated, info = env.step(np.array(action))\n",
    "    total_rewards += reward\n",
    "    total_steps += 1\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "print(\"Episode done in %d step， total reward %.2f\" % (total_steps, total_rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff4c273-09e6-403d-91bd-a1501ca0d722",
   "metadata": {},
   "source": [
    "## 包装器\n",
    "\n",
    "继承继承自Env类。它的构造函数只有一个参数，即要被“包装”的Env类的实例。为了附加额外的功能，需要重新定义想扩展的方法，例如step()或reset()。唯一的要求就是需要调用超类中的原始方法。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92905884-7357-46cf-bd03-d24795bb876e",
   "metadata": {},
   "source": [
    "ObservationWrapper：需要重新定义父类的observation(obs)方法。obs参数是被包装的环境给出的观察，这个方法需要返回给予智能体的观察。\n",
    "\n",
    "RewardWrapper：它暴露了一个reward(rew)方法，可以修改给予智能体的奖励值。\n",
    "\n",
    "ActionWrapper：需要覆盖action(act)方法，它能修改智能体传给被包装环境的动作。传给被包装环境的动作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98534dbb-2a60-4c06-ab9c-5e7cdc21c784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd195e36-ff36-4f61-9ebb-d1cfd361c12d",
   "metadata": {},
   "source": [
    "为了让它更实用，假设有一个场景，我们想要以10%的概率干涉智\r",
    "能体发出的动作流，将当前动作替换成随机动作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64ed37af-e524-4892-ad6e-82fcb0aad2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomActionWrapper(gym.ActionWrapper):\n",
    "    def __init__(self, env, p=0.1):\n",
    "        super(RandomActionWrapper, self).__init__(env)\n",
    "        self.p = p\n",
    "\n",
    "    def action(self, action):\n",
    "        if np.random.uniform(0,1,1) < self.p:\n",
    "            print(\"Action changed randomly!\")\n",
    "            return self.env.action_space.sample()\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcacecb9-9b9b-4dad-a5fb-beea90079747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward got: 9.00\n"
     ]
    }
   ],
   "source": [
    "env = RandomActionWrapper(gym.make(\"CartPole-v1\"))\n",
    "\n",
    "obs = env.reset()\n",
    "total_reward = 0.0\n",
    "\n",
    "while True:\n",
    "    obs, reward, terminated, truncated, info = env.step(0)\n",
    "    total_reward += reward\n",
    "    if terminated:\n",
    "        break\n",
    "\n",
    "print(\"Reward got: %.2f\" % total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6700b180-3969-4d21-9e76-8f88f5021213",
   "metadata": {},
   "source": [
    "## 监控器 Monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "981ac5c3-90b4-466d-9efb-14ab7c8a0071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92516c9a-f448-4e47-9278-6e3c174fc3f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Program Files\\Python39\\lib\\site-packages\\gym\\wrappers\\record_video.py:75: UserWarning: \u001b[33mWARN: Overwriting existing videos at D:\\code\\python\\reinforcement_learnging\\video folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\",render_mode='rgb_array')\n",
    "env=gym.wrappers.RecordVideo(env,video_folder='video',name_prefix='mario')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "945725a7-7d00-4a70-a377-c114a05a9b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-0.mp4.\n",
      "Moviepy - Writing video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-0.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-1.mp4.\n",
      "Moviepy - Writing video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-1.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-1.mp4\n",
      "Moviepy - Building video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-8.mp4.\n",
      "Moviepy - Writing video D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-8.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready D:\\code\\python\\reinforcement_learnging\\video\\mario-episode-8.mp4\n",
      "Reward got: 197.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "total_reward = 0.0\n",
    "\n",
    "for episode in range(10):\n",
    "    while True:\n",
    "        obs, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "        total_reward += reward\n",
    "        if terminated:\n",
    "            break\n",
    "    env.reset()\n",
    "\n",
    "print(\"Reward got: %.2f\" % total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4022ff18-1ebb-44b9-ac8e-fa561f90f410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
